<!doctype html>
<html lang="en">
<meta charset="utf-8">
<title>1. makemore: bigram</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
<style>
    body {
        font-size: 1.4em;
        font-family: 'Source Sans 3', 'Hoefler Text', Georgia, 'Times New Roman', Times, serif;
        max-width: 900px;
        margin: 1em auto 10em;
    }

    :focus {
        outline-width: 2px;
        outline-style: solid;
        outline-color: #00f;
        border-radius: 2px;
        border-color: transparent;
    }

    [aria-label] {
        position: relative;
    }

    [aria-label]:focus-within::before {
        content: attr(aria-label);
        position: absolute;
        bottom: -20px;
        font-size: 12px;
        /* right: 0; */
    }

    input, button {
        font-family: inherit;
        font-size: inherit;
        font-size: 0.8em;
    }

    pre, code, samp, textarea {
        font-family: 'Source Code Pro', ui-monospace, Menlo, Monaco, "Cascadia Mono", "Segoe UI Mono", "Roboto Mono", "Oxygen Mono", "Ubuntu Monospace", "Source Code Pro", "Fira Mono",  "Droid Sans Mono", "Courier New", monospace !important;
        font-size: 0.8em !important;
        background: lightgoldenrodyellow;
    }

    pre, textarea {
        overflow: auto;
        padding: 1em;
    }

    pre[data-error] {
        background: lightpink;
    }

    details {
        margin: 1em 0;
    }

    aside {
        background-color: lavender;
        padding: .5em .7em;
    }

    textarea {
        width: 100%;
        border: none;
        resize: none;
        text-wrap: nowrap;
    }

    /* nav {
        position: fixed;
        top: 0;
        left: 0;
        bottom: 0;
        background: lightgoldenrodyellow;
        padding: 1em;
        overflow: auto;
    } */
</style>
<article>
<h1>1. makemore: bigram</h1>

<h1 id="building-a-neural-network-from-scratch-in-javascript">Building a neural network from scratch in JavaScript</h1>

<aside>
    This is an interactive notebook. You can edit the snippets and use
    <code>print( var, label )</code>.
</aside>

<p>I really enjoyed Andrej Karpathy’s “Zero to Hero” series because in it, he
builds everything from scratch. Or almost at least. This post follows his second
video lecture, but in JS instead. While he uses PyTorch’s low level APIs, we’ll
be creating absolutely everything from scratch, without any fancy machine
learning frameworks!</p>

<p>Let’s begin with a simple neural network that learns which character is most
likely to follow given a character. A simple character-level bigram model. We
will train on names, and when done we can generate more (“makemore”) name-like
sequences.</p>

<p>First, we need to fetch a list of names and process those names into a useable
dataset.</p>

<textarea disabled rows='4'>
const response = await fetch('https://raw.githubusercontent.com/karpathy/makemore/master/names.txt');
const text = await response.text();
const names = text.split('\n');
</textarea>

<p>Now that we have an array of names, let’s create index-to-character and
character-to-index mappings. Neural networks cannot operate on characters,
we’ll need to map the characters to numbers. Additionally we’ll want to
include a character that can be used to signify the start or end of a name.
Let’s use a newline, set at index 0.</p>

<textarea disabled rows='7'>
const indexToCharMap = [ '.', ...new Set( names.join('') ) ].sort();
const stringToCharMap = {};

for ( let i = indexToCharMap.length; i--; ) {
    stringToCharMap[ indexToCharMap[ i ] ] = i;
}
</textarea>

<p>Next, let’s create the training dataset. We need pairs (bigrams) of a character
x preceding a character y. My name <code class="language-plaintext highlighter-rouge">ella</code> has 5 examples: <code class="language-plaintext highlighter-rouge">.e</code>, <code class="language-plaintext highlighter-rouge">el</code>, <code class="language-plaintext highlighter-rouge">ll</code>,
<code class="language-plaintext highlighter-rouge">la</code>, and <code class="language-plaintext highlighter-rouge">a.</code>! To do this we prepend and append the names with <code class="language-plaintext highlighter-rouge">.</code></p>

<textarea disabled rows='13'>
const xs = []; // Inputs.
const ys = []; // Targets, or labels.

for ( const name of names ) {
    const exploded = '.' + name + '.';
    let i = 1;
    while ( exploded[ i ] ) {
        xs.push( stringToCharMap[ exploded[ i - 1 ] ] );
        ys.push( stringToCharMap[ exploded[ i ] ] );
        i++;
    }
}
</textarea>

<p>That’s it! Now we have our training data. For example for <code class="language-plaintext highlighter-rouge">ella</code>, <code class="language-plaintext highlighter-rouge">x[0]</code> gives
us <code class="language-plaintext highlighter-rouge">0</code> (starting character) and <code class="language-plaintext highlighter-rouge">y[0]</code> gives us <code class="language-plaintext highlighter-rouge">5</code> (E). <code class="language-plaintext highlighter-rouge">x[1]</code> gives us <code class="language-plaintext highlighter-rouge">5</code> (E)
and <code class="language-plaintext highlighter-rouge">y[1]</code> gives us <code class="language-plaintext highlighter-rouge">12</code> (L) and so on.</p>

<p>We now want to build a neural network with a single layer, in which the weights
are a 27×27 matrix. You can see it as a table containing the probabilities of a
character in each column being followed by the character in the row. We could
enlarge the number of columns, but this is easier to visualise later.</p>

<p>The weights are trainable and should be initialised randomly to break symmetry,
otherwise all gradients will be the same. JavaScript does not have a native
matrix data type, so let’s use flat arrays with a <code class="language-plaintext highlighter-rouge">shape</code> property. For example
a <code class="language-plaintext highlighter-rouge">shape</code> of <code class="language-plaintext highlighter-rouge">[ 20, 27 ]</code> is a matrix with 20 rows and 27 columns. Let’s create
a utility function to create a matrix.</p>

<textarea disabled rows='18' data-src="utils.js">
export class FloatMatrix extends Float32Array {
    constructor( data, shape = data?.shape || [] ) {
        const length = shape.reduce( ( a, b ) => a * b, 1 );

        if  ( typeof data === 'function' ) {
            data = Array.from( { length }, data );
        }

        super( data || length );

        if ( this.length !== length ) {
            throw new Error( 'Shape does not match data length.' );
        }

        this.shape = shape;
    }
}
</textarea>

<textarea disabled rows='2'>
print( new FloatMatrix( null, [ 2, 3 ] ) );
</textarea>

<p>With <code class="language-plaintext highlighter-rouge">FloatMatrix</code>, we can now initialise our weights matrix more easily. Let’s
add random values between 1 and -1.</p>

<textarea disabled rows='4' data-src="utils.js">
export function random() {
    return Math.sqrt(-2 * Math.log(1 - Math.random())) * Math.cos(2 * Math.PI * Math.random());
}
</textarea>

<textarea disabled rows='3'>
const totalChars = indexToCharMap.length;
const W = new FloatMatrix( random, [ totalChars, totalChars ] );
</textarea>

<p>Given these weights, we now want to calculate a probability distribution for
each example in our training set. We need a way to pluck out the weights row for
each input (x) in the dataset. For example <code class="language-plaintext highlighter-rouge">x[0]</code> is <code class="language-plaintext highlighter-rouge">0</code> and needs to pluck out
the 0th row of our weights, which can then give us the probability distribution
for the next character. Our neural net will later on change the weights so the
probability for <code class="language-plaintext highlighter-rouge">y[0]</code> (E) to be a starting character gets higher.</p>

<p>An easy way to do this is to convert <code class="language-plaintext highlighter-rouge">xs</code> to a one-hot matrix (<code class="language-plaintext highlighter-rouge">xs.length</code> x
<code class="language-plaintext highlighter-rouge">totalChars</code>) and then matrix multiply that with the weights (<code class="language-plaintext highlighter-rouge">totalChars</code> x
<code class="language-plaintext highlighter-rouge">totalChars</code>) resulting in the desired <code class="language-plaintext highlighter-rouge">xs.length</code> x <code class="language-plaintext highlighter-rouge">totalChars</code> matrix where
each row is the weights for the character in <code class="language-plaintext highlighter-rouge">xs</code>. Since the one-hot matrix is
all zeros except for one column, it effectively plucks out the row with that
column index from the weights matrix.</p>

<p>First, let’s one-hot encode <code class="language-plaintext highlighter-rouge">xs</code>.</p>

<textarea disabled rows='6' data-src="utils.js">
export function oneHot( a, length ) {
    const B = new FloatMatrix( null, [ a.length, length ] );
    for ( let i = a.length; i--; ) B[ i * length + a[ i ] ] = 1;
    return B;
}
</textarea>

<textarea disabled rows='2'>
const XOneHot = oneHot( xs, indexToCharMap.length );
</textarea>

<p>Now let’s multiply it by the weights. For that we need to implement matrix
multiplication.</p>

<textarea disabled rows='22' data-src="utils.js">
export function matMul(A, B) {
    const [ m, n ] = A.shape;
    const [ p, q ] = B.shape;
    const C = new FloatMatrix( null, [ m, q ] );

    if ( n !== p ) {
        throw new Error( 'Matrix dimensions do not match.' );
    }

    for ( let m_ = m; m_--; ) {
        for ( let q_ = q; q_--; ) {
            let sum = 0;
            for ( let n_ = n; n_--; ) {
                sum += A[m_ * n + n_] * B[n_ * q + q_];
            }
            C[m_ * q + q_] = sum;
        }
    }

    return C;
}
</textarea>

<textarea disabled rows='2'>
const Wx = matMul( XOneHot, W );
</textarea>

<p>This is the only layer we will have in our neural network for now. Just a
linear layer without a bias, a really simple and dumb neural network.</p>

<p>Now we have the weights for each input, but we somehow want these numbers to
represent the probabilities for the next character. For this we can use the
softmax, which scales numbers into probabilities. So for each row of <code class="language-plaintext highlighter-rouge">Wx</code> we
want to call the softmax function so that each row is a probability distribution
summing to 1. You can see <code class="language-plaintext highlighter-rouge">Wx</code> a bit as “log-counts” (also called “logits”) that
can be exponentiated to get fake “counts” (the occurrences of a character for a
previous character). To get probabilities, they can be normalised by dividing
over the sum. This is basically what softmax does.</p>

<p>First we need to create a softmax function. We want to calculate the softmax
for every row. We’re subtracting the maximum before exponentiating for
numerical stability.</p>

<textarea disabled rows='22' data-src="utils.js">
export function softmaxByRow( A ) {
    const [m, n] = A.shape;
    const B = new FloatMatrix( null, A.shape );
    for ( let m_ = m; m_--; ) {
        let max = -Infinity;
        for ( let n_ = n; n_--; ) {
            const value = A[m_ * n + n_];
            if (value > max) max = value;
        }
        let sum = 0;
        for ( let n_ = n; n_--; ) {
            const i = m_ * n + n_;
            // Subtract the max to avoid overflow
            sum += B[i] = Math.exp(A[i] - max);
        }
        for ( let n_ = n; n_--; ) {
            B[m_ * n + n_] /= sum;
        }
    }
    return B;
}
</textarea>

<textarea disabled rows='2'>
const probs = softmaxByRow( Wx );
</textarea>

<p>Now that we have probabilities for each row (summing to 1), we can use this
later to sample from the model.</p>

<h2 id="evaluating-the-model">Evaluating the model</h2>

<p>We now need a way evaluate the model mathematically. We can do this by creating
a function to calculate a loss. As long as it’s all differentiable, we can then
calculate the gradients with respect to the weights matrix and tune it, giving
us a better loss and thus better probabilities. The idea is that we can keep
doing this and iteratively tune the weights matrix to give one with as low a
loss as possible.</p>

<p>The loss function we will use here is called the negative log likelihood, which
measures how well the data fits our model.</p>

<p>First, we need to pluck out the probabilities given the characters in <code class="language-plaintext highlighter-rouge">y</code>, also
called the labels or targets. If you do this with untrained weights, you’ll
notice that these probabilities are not very good. Then we calculate the log
probabilities or likelihoods by taking the log of each probability. To get the
log likelihood of everything together, we take the mean.</p>

<p>Here’s how to do it in JS in a single loop.</p>

<textarea disabled rows='12' data-src="utils.js">
export function negativeLogLikelihood( probs, ys ) {
    const [m, n] = probs.shape;
    let sum = 0;
    for ( let m_ = m; m_--; ) {
        // Sum the logProbs (log likelihoods) of the correct label.
        sum += Math.log( probs[ m_ * n + ys[ m_ ] ] );
    }
    const mean = sum / m;
    // Mean negative log likelihood.
    return - mean;
}
</textarea>

<textarea disabled rows='4'>
// Let's keep track of the losses.
const loss = negativeLogLikelihood( probs, ys );
const losses = [ loss ];
</textarea>

<h1 id="backward-pass-to-calculate-gradients">Backward pass to calculate gradients</h1>

<p>Now we want to calculate the gradients for the weights matrix. We’ll split this
into two: first calculate the gradients for <code class="language-plaintext highlighter-rouge">Wx</code>, and then from those the
gradients for <code class="language-plaintext highlighter-rouge">W</code>.</p>

<p>Now this is not explained in Karpathy’s
<a href="https://www.youtube.com/watch?v=PaCmpygFfXo">second video</a>,
he’s just using PyTorch’s backward. We can’t do that cause this is hardcore from
scratch! Fortunately, when using the softmax activation combined with
cross-entropy loss, the gradient simplifies to the difference between our
predicted probabilities and the actual labels, which he explains in
<a href="https://youtu.be/q8SA3rM6ckI?si=vXBKdMh7sSO44VJT&amp;t=5187">part 4</a>.
This is only for a single example, so when spreading the gradient we also need
to divide by the number of rows.</p>

<textarea disabled rows='14' data-src="utils.js">
export function softmaxCrossEntropyGradient( probs, ys ) {
    const [m, n] = probs.shape;
    const gradient = new FloatMatrix( probs );
    for ( let m_ = m; m_--; ) {
        // Subtract 1 for the gradient of the correct label.
        gradient[ m_ * n + ys[ m_ ] ] -= 1;
        for ( let n_ = n; n_--; ) {
            // Divide by the number of rows.
            gradient[ m_ * n + n_ ] /= m;
        }
    }
    return gradient;
}
</textarea>

<textarea disabled rows='2'>
const WxGradient = softmaxCrossEntropyGradient( probs, ys );
</textarea>

<p>Now the easier one: the derivative of a matrix multiplication <code class="language-plaintext highlighter-rouge">A * B</code> with
respect to the second parameter is <code class="language-plaintext highlighter-rouge">dB = A^T * dAB</code>.</p>

<textarea disabled rows='13' data-src="utils.js">
export function transpose( A ) {
    const [ m, n ] = A.shape;
    const B = new FloatMatrix( null, [ n, m ] );

    for ( let m_ = m; m_--; ) {
        for ( let n_ = n; n_--; ) {
            B[n_ * m + m_] = A[m_ * n + n_];
        }
    }

    return B;
}
</textarea>

<textarea disabled rows='2'>
const WGradient = matMul( transpose( XOneHot ), WxGradient );
</textarea>

<p>And finally, we can update the weights using these gradients! Let’s first
set a learning rate of 10.</p>

<textarea disabled rows='2'>
const learningRate = 10;
</textarea>

<textarea disabled rows='3'>
for ( let i = W.length; i--; ) W[ i ] -= learningRate * WGradient[ i ];
print( W );
</textarea>

<p>If we now calculate the loss again, it should be lower!</p>

<textarea disabled rows='4'>
const newProbs = softmaxByRow( matMul( XOneHot, W ) );
const newLoss = negativeLogLikelihood( newProbs, ys );
print( loss, 'oldLoss' );
</textarea>

<h2 id="iterate">Iterate</h2>

<p>Now we need to iterate over this many times.</p>

<textarea disabled rows='13'>
async function iteration() {
    const Wx = await matMul( XOneHot, W );
    const probs = softmaxByRow( Wx );

    losses.push( negativeLogLikelihood( probs, ys ) );

    // Backpropagation.
    const WxGradient = softmaxCrossEntropyGradient( probs, ys );
    const WGradient = await matMul( transpose( XOneHot ), WxGradient );

    for ( let i = W.length; i--; ) W[ i ] -= learningRate * WGradient[ i ];
}
</textarea>

<p>Just so we can visualise this better, let’s create two graphs using
<a href="https://plotly.com/javascript/">Plotly</a>:</p>

<ul>
  <li>The losses for each iteration.</li>
  <li>A table with all bigram combinations, darker means a higher occurrence.</li>
</ul>

<textarea disabled rows='40'>
export { default as Plotly } from 'https://cdn.jsdelivr.net/npm/plotly.js-dist@2.26.2/+esm';
async function updateLossGraph( element = document.createElement('div') ) {
    return await Plotly.react(
        element,
        [ { x: losses.map( ( _, i ) => i ), y: losses } ],
        {
            width: 500, height: 500,
            yaxis: { title: 'Loss', type: 'log' },
            xaxis: { title: 'Iterations' }
        },
        { displayModeBar: false }
    );
}
async function updateBigramTable( element = document.createElement('div') ) {
    const r = indexToCharMap.map( ( _, i ) => i )
    return await Plotly.react(
        element,
        [ {
            x: indexToCharMap, y: indexToCharMap,
            z: r.map((_, m_) => r.map((_, n_) => Math.exp(W[m_ * r.length + n_]))),
            type: 'heatmap', showscale: false,
            colorscale: [ [ 0, 'white' ], [ 1, 'black' ] ],
        } ],
        {
            width: 500, height: 500,
            yaxis: { tickvals: [], autorange: 'reversed' },
            xaxis: { tickvals: [], },
            margin: { t: 10, b: 10, l: 10, r: 10 },
            annotations: r.map((_, m_) => r.map((_, n_) => ({
                x: indexToCharMap[n_],
                y: indexToCharMap[m_],
                text: `${indexToCharMap[m_]}${indexToCharMap[n_]}`,
                showarrow: false,
                font: { color: 'white' }
            }))).flat(),
        },
        { displayModeBar: false }
    );
}
</textarea>

<p>For each iteration, let’s update the graphs.</p>

<textarea disabled rows='12' id="iteration">
const iterations = 10;
const lossGraph = await updateLossGraph();
const bigramTable = await updateBigramTable();
print( [ lossGraph, bigramTable ] );
for ( let i = iterations; i--; ) {
    await iteration();
    await updateLossGraph( lossGraph );
    await updateBigramTable( bigramTable );
    // Wait an animation frame to make sure the graphs are updated.
    await new Promise( requestAnimationFrame );
}
</textarea>

<p>This works, but it’s very slow!</p>

<h2 id="bonus-gpu">Bonus! GPU!</h2>

<p>Running matrix multiplication on the CPU is slow. Even running it unoptimised on
the GPU will be much faster. It took me a while to recreate matrix
multiplication with WebGPU. After crashing my computer a few times (I swear it
did!), I ended up with some code that works. Here’s the
<a href="https://href.li/?https://github.com/ellatrix/micrograd/blob/main/matmul-gpu.js">code</a>,
and the
<a href="https://href.li/?https://github.com/ellatrix/micrograd/blob/main/matmul.wgsl">shader</a>.
No external libraries, so we’re not cheating. This only works in Chrome and Edge
though.</p>

<textarea disabled rows='3'>
const { GPU } = await import( new URL( './matmul-gpu.js', location ) );
const matMul = ( await GPU() )?.matMul || matMul;
</textarea>

<p>Let’s now go <a href="#iteration">back to iterating</a>, set it to <mark>200</mark>, and
run it again until the loss is below <mark>2.5</mark>.</p>

<h2 id="sampling">Sampling</h2>

<p>To sample from the model, we need to input a single character that is
one-hot encoded. Matrix multiply that with the weights, then calculate the
probabilities as before. Then we can take a random number between 0 and 1
and pick from the probabilities. Higher probabilities have a larger “surface
area” in the sample function.</p>

<textarea disabled rows='9' data-src="utils.js">
export function sample(probs) {
    const sample = Math.random();
    let total = 0;
    for ( let i = probs.length; i--; ) {
        total += probs[ i ];
        if ( sample < total ) return i;
    }
}
</textarea>

<textarea disabled rows='11'>
async function sampleName() {
    const indices = [ 0 ];
    do {
        const context = indices.slice( -1 );
        const Wc = await matMul( oneHot( context, indexToCharMap.length ), W );
        const probs = softmaxByRow( Wc );
        indices.push( sample( probs ) );
    } while ( indices[ indices.length - 1 ] );
    return indices;
}
</textarea>

<textarea disabled rows='5'>
const iterations = 10;
for ( let i = iterations; i--; ) {
    print( (await sampleName()).map( ( i ) => indexToCharMap[ i ] ).join( '' ) );
}
</textarea>

<p>The output is not great, but it’s also not completely random. If you’re
curious, run this notebook again without training and you’ll see that
sampling with untrained weights is completely random.</p>

<p>In the next notebook we’ll see how to enlarge the network, get a better
loss, and better samples.</p>


</article>
<script src="lib/acorn.min.js"></script>
<script>
    const scripts = [ ...document.querySelectorAll('textarea') ];
    let queue = Promise.resolve();

    scripts.forEach( ( script ) => {
        const outputwrapper = document.createElement('div');
        const div = document.createElement('details');
        div.open = true;
        const button = document.createElement('button');
        button.innerText = 'Run';
        const pre = document.createElement('textarea');
        const iInput = document.createElement('input');
        const float = document.createElement('summary');
        float.tabIndex = -1;
        iInput.type = 'number';
        iInput.value = script.dataset.iterations;

        div.onkeydown = ( event ) => {
            if ( event.key === 'Enter' && event.shiftKey ) {
                event.preventDefault();
                button.click();
            }
        };

        function stringifyArray( array ) {
            array = Array.from( array );
            // Only show first 3 and last 3 if larger than 6.
            if ( array.length > 6 ) {
                return `[ ${array.slice(0,3).join(', ')}, ..., ${array.slice(-3).join(', ')}]`;
            }
            return `[ ${array.join(', ')} ]`;
        }

        function stringify( data ) {
            if ( ( window.FloatMatrix && data instanceof FloatMatrix ) || ( window.Int32Array && data instanceof Int32Array ) ) {
                if ( data.shape.length === 1 ) return `${data.constructor.name}(${data.length}) ${ stringifyArray( data ) }`;

                // If larger than 6 rows, get the first 3 and last 3.
                if (data.shape.length === 3) {
                    const [depth, height, width] = data.shape;
                    const slices = [];
                    for (let d = 0; d < (depth > 6 ? 3 : depth); d++) {
                        const rows = [];
                        for (let h = 0; h < (height > 6 ? 3 : height); h++) {
                            const row = [];
                            for (let w = 0; w < width; w++) {
                                row.push(data[d * height * width + h * width + w]);
                            }
                            rows.push(stringifyArray(row));
                        }
                        if (height > 6) {
                            rows.push('...');
                            for (let h = height - 3; h < height; h++) {
                                const row = [];
                                for (let w = 0; w < width; w++) {
                                    row.push(data[d * height * width + h * width + w]);
                                }
                                rows.push(stringifyArray(row));
                            }
                        }
                        slices.push(`[\n  ${rows.join(',\n  ')}\n ]`);
                    }
                    if (depth > 6) {
                        slices.push('...');
                        for (let d = depth - 3; d < depth; d++) {
                            const rows = [];
                            for (let h = 0; h < (height > 6 ? 3 : height); h++) {
                                const row = [];
                                for (let w = 0; w < width; w++) {
                                    row.push(data[d * height * width + h * width + w]);
                                }
                                rows.push(stringifyArray(row));
                            }
                            if (height > 6) {
                                rows.push('...');
                                for (let h = height - 3; h < height; h++) {
                                    const row = [];
                                    for (let w = 0; w < width; w++) {
                                        row.push(data[d * height * width + h * width + w]);
                                    }
                                    rows.push(stringifyArray(row));
                                }
                            }
                            slices.push(`[\n  ${rows.join(',\n  ')}\n ]`);
                        }
                    }
                    return `${data.shape.join('×')} [\n${slices.join(',\n')}\n]`;
                } else if (data.shape.length === 2) {
                    if (data.shape[0] > 6) {
                        const rows = [];
                        for (let m = 0; m < 3; m++) {
                            const row = [];
                            for (let n = 0; n < data.shape[1]; n++) {
                                row.push(data[m * data.shape[1] + n]);
                            }
                            rows.push(stringifyArray(row));
                        }
                        rows.push('...');
                        for (let m = data.shape[0] - 3; m < data.shape[0]; m++) {
                            const row = [];
                            for (let n = 0; n < data.shape[1]; n++) {
                                row.push(data[m * data.shape[1] + n]);
                            }
                            rows.push(stringifyArray(row));
                        }
                        return `${data.shape.join('×')} [
 ${rows.join(',\n ')}
]`;
                    }

                    const rows = [];
                    for (let m = 0; m < data.shape[0]; m++) {
                        const row = [];
                        for (let n = 0; n < data.shape[1]; n++) {
                            row.push(data[m * data.shape[1] + n]);
                        }
                        rows.push(stringifyArray(row));
                    }
                    return `${data.shape.join('×')} [
 ${rows.join(',\n ')}
]`;
                }
            }

            function hellip( string, condition ) {
                return condition ? `${string.slice(0,-1)}…` : string;
            }

            if ( typeof data === 'string' ) return hellip( JSON.stringify( data.slice( 0, 100 ) ), data.length > 100 );
            if ( typeof data === 'number' ) return data.toString();
            if ( typeof data === 'boolean' ) return data.toString();
            if ( typeof data === 'undefined' ) return 'undefined';
            if ( data === null ) return 'null';
            if ( data instanceof Error ) return data.toString();
            if ( data instanceof Array || data instanceof Float32Array || data instanceof Int32Array ) {
                return `${ data.constructor.name }(${data.length}) ${ stringifyArray( data ) }`;
            }
            if ( data instanceof Set ) {
                return `Set(${data.size}) ${ stringifyArray( [...data] ) }`;
            }
            if ( typeof data === 'object' ) return JSON.stringify( data, ( key, value ) => {
                if ( ! key ) return value;
                if ( typeof value === 'function' ) return '[Function]';
                if ( typeof value === 'object' ) return '[Object]';
                return value;
            }, 1 ).replace( /\n\s*/g, ' ' );
            if ( typeof data === 'function' ) return `Function`;
        }

        button.tabIndex = -1;
        button.onclick = async () => {
            button.disabled = true;
            outputwrapper.innerHTML = '';
            const output = document.createElement('pre');
            outputwrapper.append( output );
            outputwrapper.focus();
            pre?.editor.save();
            let text = pre.value;

            const ast = acorn.parse(text, { ecmaVersion: 'latest', sourceType: 'module' });
            console.log(ast);

            // collect all top-level declarations names.
            const declarations = [];
            for ( const dt of ast.body ) {
                if ( dt.type === 'VariableDeclaration' ) {
                    for ( const decl of dt.declarations ) {
                        switch ( decl.id.type ) {
                            case 'Identifier':
                                declarations.push( decl.id.name );
                                break;
                            case 'ObjectPattern':
                                for ( const prop of decl.id.properties ) {
                                    declarations.push( prop.key.name );
                                }
                                break;
                            case 'ArrayPattern':
                                for ( const elem of decl.id.elements ) {
                                    declarations.push( elem.name );
                                }
                                break;
                        }
                    }
                } else if ( dt.type === 'FunctionDeclaration' ) {
                    declarations.push( dt.id.name );
                } else if ( dt.type === 'ClassDeclaration' ) {
                    declarations.push( dt.id.name );
                }
            }

            text += `;${declarations.map( decl =>
                `window.${decl} = ${decl};print( ${decl}, '${decl}' );`
            ).join( '\n' )}`;

            const blob = new Blob( [ text ], { type: 'text/javascript' } );

            let i = parseInt( iInput.value, 10 ) || 1;

            const promiseExecutor = async (resolve, reject) => {
                const url = URL.createObjectURL(blob);
                print = function ( data, key = '' ) {
                    const line = document.createElement('div');
                    console.log(data);
                    if ( data instanceof Element ) {
                        if (!output.contains(data)) {
                            line.appendChild( data );
                        }
                    } else if ( Array.isArray( data ) && data.every( child => child instanceof Element ) ) {
                        line.style.display = 'flex';
                        data.forEach( child => line.appendChild( child ) );
                    } else {
                        if ( key ) {
                            const b = document.createElement('b');
                            b.textContent = key;
                            line.appendChild( b );
                        }
                        line.appendChild(
                            document.createTextNode( ( key ? ': ' : '' ) + stringify( data ) )
                        );
                    }
                    output.appendChild( line );
                }
                try {
                    const imports = await import(url);
                    Object.keys(imports).forEach((key) => {
                        window[key] = imports[key];
                        print(imports[key], key);
                    });
                } catch (error) {
                    output.dataset.error = true;
                    print(error);
                }

                resolve();
            };

            queue = queue.then( () => new Promise( promiseExecutor ) ).then( () => {
                button.disabled = false;
            } );
        };

        div.onfocus = () => {
            div.open = true;
        };

        pre.button = button;
        pre.style.width = '100%';
        pre.value = script.value.trim();
        pre.rows = pre.value.split( '\n' ).length;
        iInput.style.width = '4em';
        if ( script.dataset.src ) {
            const code = document.createElement('code');
            code.textContent = script.dataset.src;
            float.appendChild( code );
            float.appendChild( document.createTextNode( ' ' ) );
        }
        float.appendChild( button );
        if ( script.dataset.iterations !== undefined ) {
            float.appendChild( document.createTextNode( ' × ' ) );
            float.appendChild( iInput );
        }
        div.appendChild( float );
        div.appendChild( pre );
        div.id = script.id;
        script.replaceWith( div );
        div.after( outputwrapper );
    } );

    const article = document.querySelector('article');

    [...article.children].forEach( ( block ) => {
        block.tabIndex = 0;
        block.setAttribute( 'aria-label', 'Shift+Enter to continue' );
    } );

    article.addEventListener('keydown', ( event ) => {
        if ( event.key === 'Enter' && event.shiftKey && ! event.defaultPrevented ) {
            document.activeElement.closest('[aria-label]').nextElementSibling?.focus();
        }
    })

    article.firstElementChild.focus();
</script>
<link rel="stylesheet" href="lib/codemirror.min.css" integrity="sha512-uf06llspW44/LZpHzHT6qBOIVODjWtv4MxCricRxkzvopAlSWnTf6hpZTFxuuZcuNE9CBQhqE0Seu1CoRk84nQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<script src="lib/codemirror.min.js" integrity="sha512-8RnEqURPUc5aqFEN04aQEiPlSAdE0jlFS/9iGgUyNtwFnSKCXhmB6ZTNl7LnDtDWKabJIASzXrzD0K+LYexU9g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="lib/javascript.min.js" integrity="sha512-I6CdJdruzGtvDyvdO4YsiAq+pkWf2efgd1ZUSK2FnM/u2VuRASPC7GowWQrWyjxCZn6CT89s3ddGI+be0Ak9Fg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<style>
    .CodeMirror, .CodeMirror-scroll {
        height: auto;
        background: none;
    }
</style>
<script>
    document.querySelectorAll('textarea').forEach((textarea) => {
        textarea.editor = CodeMirror.fromTextArea(textarea, {
            mode: 'javascript',
            viewportMargin: Infinity,
            // theme: 'material',
            extraKeys: {
                'Shift-Enter': (cm) => {
                    textarea.button.focus();
                },
            },
        });
    })
</script>








<!-- Debug: 
    Original: /autograd
    After remove_first: autograd
    After relative_url: /autograd
  -->
  <a href="autograd">Next: 2. Autograd</a>

<nav>
    <!-- <details> -->
        <!-- <summary>Table of contents</summary> -->
        <ul>
            
            <li><a href="">1. makemore: bigram</a></li>
            
            <li><a href="autograd">2. Autograd</a></li>
            
            <li><a href="makemore-MLP">3. makemore: MLP</a></li>
            
            <li><a href="makemore-learning-rate">3.1. makemore: Learning Rate</a></li>
            
            <li><a href="makemore-initialisation">3.2. makemore: Initialisation</a></li>
            
            <li><a href="makemore-batch-norm">3.3. makemore: Batch Norm</a></li>
            
            <li><a href="makemore-layer-organisation">3.4. makemore: Layer Organisation</a></li>
            
            <li><a href="makemore-wave-net">5. makemore: Wave Net</a></li>
            
        </ul>
    <!-- </details> -->
</nav>
<script async src="lib/tex-mml-chtml.js"></script>
