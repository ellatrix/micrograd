<p>Click <em>Sample</em>, and you'll see the output is very random, because the
neural network hasn't trained yet. Now click <em>Run</em> to start training (<a
href="https://raw.githubusercontent.com/karpathy/makemore/master/names.txt">data</a>).
When the loss is lower, click <em>Sample</em> again, and you'll see the output
has gotten a bit better. Try to reach a loss of 2.4 or lower, but it's possible
to get it under 2.3!</p>
<p>This neural network is written in JS with zero dependencies (apart from the plot library).</p>
<input type="text" id="learningRateInput" value="0.1">
<button id="runButton">Run</button>
<code>training loss: </code><samp id="trlossOutput">x.xxxx</samp>;
<code>dev loss: </code><samp id="devlossOutput">x.xxxx</samp>;
<code>iterations: </code><samp id="iterationsOutput">x</samp><hr>
<button id="sampleButton">Sample</button>
<samp id="sampleOutput"></samp>
<hr>
<div style="float: left;" id="table"></div>
<div style="float: left;" id="losses"></div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/plotly.js/2.26.0/plotly.min.js"></script>
<script src="matmul-cpu.js"></script>
<script src="matmul-gpu.js"></script>
<script src="matrix.js"></script>
<script>
    ( async () => {
        const res = await fetch('https://raw.githubusercontent.com/karpathy/makemore/master/names.txt');
        const text = await res.text();
        Value.gpu = await GPU();

        const indexToCharMap = [ '.', ...new Set( text ) ].sort().slice( 1 );
        const totalChars = indexToCharMap.length;
        const stringToCharMap = {};

        for ( let i = totalChars; i--; ) {
            stringToCharMap[ indexToCharMap[ i ] ] = i;
        }

        function createTable( C ) {
            Plotly.react('table', [
                {
                    // get even indices from C.
                    x: Array.from( C.data ).filter( ( _, i ) => i % 2 ),
                    // get uneven indices from C.
                    y: Array.from( C.data ).filter( ( _, i ) => ! ( i % 2 ) ),
                    text: indexToCharMap,
                    mode: 'markers+text',
                    type: 'scatter',
                    name: 'Embedding',
                    marker: {
                        size: 14,
                        color: '#fff',
                        line: {
                            color: 'rgb(0,0,0)',
                            width: 1
                        }
                    }
                }
            ], {
                title: 'Embedding',
                width: 600,
                height: 600,
            });
        }

        // Hyper parameters.
        const embeddingDimensions = 2;
        const neurons = 100;
        const batchSize = 2 ** 6;
        const blockSize = 3;

        function buildDataSet( words ) {
            let X = [];
            let Y = [];

            for ( const name of words ) {
                const context = '.'.repeat( blockSize ) + name + '.';
                let i = blockSize;
                while ( context[ i ] ) {
                    const x = context.slice( i - blockSize, i );
                    const y = context[ i ];
                    X.push( ...[ ...x ].map( ( char ) => stringToCharMap[ char ] ) );
                    Y.push( stringToCharMap[ y ] );
                    i++;
                }
            }

            X = new Int32Array( X );
            Y = new Int32Array( Y );
            X.shape = [ X.length / blockSize, blockSize ];
            Y.shape = [ Y.length ];

            return [ X, Y ];
        }

        const names = text.split( '\n' );
        const n1 = Math.floor( names.length * 0.8 );
        const n2 = Math.floor( names.length * 0.9 );

        const [ Xtr, Ytr ] = buildDataSet( names.slice( 0, n1 ) );
        const [ Xdev, Ydev ] = buildDataSet( names.slice( n1, n2 ) );
        const [ Xte, Yte ] = buildDataSet( names.slice( n2 ) );

        const C = new Variable( random( [ totalChars, embeddingDimensions ] ) );
        const W1 = new Variable( random( [ embeddingDimensions * blockSize, neurons ], (5/3)/((embeddingDimensions * blockSize)**0.5) ) );
        const b1 = new Variable( random( [ neurons ], 0.01 ) );
        const W2 = new Variable( random( [ neurons, totalChars ], 0.01 ) );
        const b2 = new Variable( random( [ totalChars ], 0.01 ) );

        const params = [ C, W1, b1, W2, b2 ];

        createTable( C )

        const iterations = 100;
        const batchIterations = 100;

        let totalIterations = 0;
        let running = false;

        function logitFn( X ) {
            const embedding = C.gather( X ).reshape( ( shape ) => [ shape[ 0 ], shape[ 1 ] * shape[ 2 ] ] );
            const h = embedding.matMul( W1, b1 ).tanh();
            return h.matMul( W2, b2 );
        }

        function lossFn( X, Y ) {
            return logitFn( X ).softmaxCrossEntropy( oneHot( Y, totalChars ) );
        }

        const losses = [];
        const trainingLosses = [];
        const devLosses = [];

        function createLossesGraph() {
            Plotly.react('losses', [
                {
                    y: losses,
                    name: 'Batch losses',
                    hoverinfo: 'none'
                },
                {
                    y: trainingLosses,
                    x: Array.from( trainingLosses ).map( ( _, i ) => ( i + 1 ) * batchIterations ),
                    name: 'Training losses',
                },
                {
                    y: devLosses,
                    x: Array.from( devLosses ).map( ( _, i ) => ( i + 1 ) * batchIterations ),
                    name: 'Dev losses',
                }
            ], {
                title: 'Losses',
                width: 600,
                height: 600,
                yaxis: {
                    title: 'Loss',
                    type: 'log'
                },
                xaxis: {
                    title: 'Iterations'
                }
            });
        }

        createLossesGraph();

        runButton.onclick = () => {
            if ( running ) {
                running = false;
                runButton.textContent = 'Run';
                learningRateInput.disabled = false;
                return;
            }

            running = true;
            runButton.textContent = 'Stop';
            learningRateInput.disabled = true;

            const learningRate = parseFloat( learningRateInput.value ) || 0.1;
            const singleRun = async () => {
                let bi = 0;
                for ( let bi = 0; bi < batchIterations; bi++ ) {
                    const indices = Int32Array.from( { length: batchSize }, () => Math.random() * Xtr.shape[ 0 ] );
                    indices.shape = [ indices.length ];
                    const Xbatch = gather( Xtr, indices );
                    const Ybatch = gather( Ytr, indices );
                    const loss = lossFn( Xbatch, Ybatch );
                    losses.push( ( await loss.forward() )[ 0 ] );
                    await loss.backward();
                    for ( const param of params ) {
                        for ( let i = param.data.length; i--; ) {
                            param.data[ i ] -= learningRate * param.grad[ i ];
                        }
                    }
                    totalIterations++;
                    createTable( C );
                    createLossesGraph();
                }

                iterationsOutput.innerText = totalIterations;

                const trainingLoss = ( await lossFn( Xtr, Ytr ).forward() )[0];
                trainingLosses.push( trainingLoss );
                trlossOutput.innerText = trainingLoss.toFixed( 4 );

                createLossesGraph();

                const devLoss = ( await lossFn( Xdev, Ydev ).forward() )[0];
                devLosses.push( devLoss );
                devlossOutput.innerText = ( await lossFn( Xdev, Ydev ).forward() )[0].toFixed( 4 );

                createLossesGraph();
            }

            let i = 0;

            const callback = async () => {
                if ( running && i++ < iterations ) {
                    await singleRun();
                    requestAnimationFrame( callback );
                } else {
                    running = false;
                    runButton.textContent = 'Run';
                    learningRateInput.disabled = false;
                }
            }

            requestAnimationFrame( callback );
        }

        sampleButton.onclick = async () => {
            const names = [];

            for (let i = 0; i < 5; i++) {
                let out = Array( blockSize ).fill( 0 );

                do {
                    const context = clone( out.slice( -blockSize ), [ 1, blockSize ] );
                    const logits = await logitFn( context ).forward();
                    const probs = softmaxByRow( logits );
                    const ix = sample( probs );
                    out.push( ix );
                } while ( out[ out.length - 1 ] !== 0 );

                names.push( out.slice( blockSize, -1 ).map( ( i ) => indexToCharMap[ i ] ).join( '' ) );
            }

            sampleOutput.innerText = names.join( ', ' );
        }
    })();
</script>