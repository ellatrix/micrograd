<!doctype html>
<html lang="en">
<meta charset="utf-8">
<title>3. makemore: MLP</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
<style>
    body {
        font-size: 1.4em;
        font-family: 'Source Sans 3', 'Hoefler Text', Georgia, 'Times New Roman', Times, serif;
        max-width: 900px;
        margin: 1em auto 10em;
    }

    :focus {
        outline-width: 2px;
        outline-style: solid;
        outline-color: #00f;
        border-radius: 2px;
        border-color: transparent;
    }

    [aria-label] {
        position: relative;
    }

    [aria-label]:focus-within::before {
        content: attr(aria-label);
        position: absolute;
        bottom: -20px;
        font-size: 12px;
        /* right: 0; */
    }

    input, button {
        font-family: inherit;
        font-size: inherit;
        font-size: 0.8em;
    }

    pre, code, samp, textarea {
        font-family: 'Source Code Pro', ui-monospace, Menlo, Monaco, "Cascadia Mono", "Segoe UI Mono", "Roboto Mono", "Oxygen Mono", "Ubuntu Monospace", "Source Code Pro", "Fira Mono",  "Droid Sans Mono", "Courier New", monospace !important;
        font-size: 0.8em !important;
        background: lightgoldenrodyellow;
    }

    pre, textarea {
        overflow: auto;
        padding: 1em;
    }

    pre[data-error] {
        background: lightpink;
    }

    details {
        margin: 1em 0;
    }

    aside {
        background-color: lavender;
        padding: .5em .7em;
    }

    textarea {
        width: 100%;
        border: none;
        resize: none;
        text-wrap: nowrap;
    }

    /* nav {
        position: fixed;
        top: 0;
        left: 0;
        bottom: 0;
        background: lightgoldenrodyellow;
        padding: 1em;
        overflow: auto;
    } */
</style>
<article>
<h1>3. makemore: MLP</h1>

<aside>
    This covers the <a href="https://www.youtube.com/watch?v=TCH_1BHY58I">Building makemore Part 2: MLP</a> video.
</aside>

<p>We will reuse the following functions from previous chapters.</p>

<textarea disabled rows='3' data-src="utils.js">
import { GPU } from './matmul-gpu.js';
export const { matMul, scatterAdd, batchMatMul, batchSoftmaxRowTril } = await GPU();
</textarea>

<textarea disabled rows='28' data-src="utils.js">
const matrixMixin = (Base) => class extends Base {
    #shape = new Int32Array();
    constructor(data, ...args) {
        super(data, ...args);
        this.shape = data?.shape ?? [ this.length ];
    }
    get shape() {
        return Array.from( this.#shape );
    }
    set shape( shape ) {
        if ( typeof shape === 'function' ) shape = shape( this.shape );
        if (this.length !== shape.reduce((a, b) => a * b, 1))
            throw new Error('Shape does not match data length.');
        this.#shape = new Int32Array( shape );
    }
    reshape( shape ) {
        this.shape = shape;
        return this;
    }
};
export class FloatMatrix extends matrixMixin(Float32Array) {}
export class IntMatrix extends matrixMixin(Int32Array) {}

export function createFloatMatrix( shape, fn ) {
    const length = shape.reduce((a, b) => a * b, 1);
    return new FloatMatrix( fn ? Array.from( { length }, fn ) : length ).reshape( shape );
}
</textarea>

<p>In the first chapter, we created a bigram model, but it didn’t produce very
name-like sequences. The problem is that it was only looking at pairs of
characters, and didn’t consider characters further back. The problem with the
bigram model is that the table will grow exponentially for each character of
added context. For example, to look at trigrams (3 characters), we would need
a table that is 27x27x27 = 19683 entries. With 4 characters (4-grams) the table
would grow to 27^4 = 531441 entries.</p>

<p>Let’s implement <a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A Neural Probabilistic Language
Model</a>, Bengio et al. 2003.</p>

<p>Let’s again fetch the names as we did in the first chapter.</p>

<textarea disabled rows='4'>
const response = await fetch('https://raw.githubusercontent.com/karpathy/makemore/master/names.txt');
const text = await response.text();
const names = text.split('\n');
</textarea>

<p>And we again make the index-to-character and character-to-index mappings.</p>

<textarea disabled rows='7'>
const indexToCharMap = [ '.', ...new Set( names.join('') ) ].sort();
const stringToCharMap = {};

for ( let i = indexToCharMap.length; i--; ) {
    stringToCharMap[ indexToCharMap[ i ] ] = i;
}
</textarea>

<p>Now we build the dataset. But unlike last time, we want to dynamically build the
dataset based on the context length. We’ll call this the block size. It’s a
hyper parameter we can tune to experiment with later to try to get a better
result.</p>

<textarea disabled rows='22' data-src="utils.js">
export function buildDataSet( names, stringToCharMap, blockSize ) {
    let X = [];
    let Y = [];

    for ( const name of names ) {
        const context = '.'.repeat( blockSize ) + name + '.';
        let i = blockSize;
        while ( context[ i ] ) {
            const x = context.slice( i - blockSize, i );
            const y = context[ i ];
            X.push( ...[ ...x ].map( ( char ) => stringToCharMap[ char ] ) );
            Y.push( stringToCharMap[ y ] );
            i++;
        }
    }

    return [
        new IntMatrix( X ).reshape( [ X.length / blockSize, blockSize ] ),
        new IntMatrix( Y ).reshape( [ Y.length ] )
    ];
}
</textarea>

<textarea disabled rows='3'>
const hyperParameters = { blockSize: 3 };
const [ X, Y ] = buildDataSet( names, stringToCharMap, hyperParameters.blockSize );
</textarea>

<p>Instead of x (the inputs) being the same shape as y (the targets or labels), x
is now y.length x blockSize matrix.</p>

<p>We now want to create an embedding matrix. Each character can be embedded in
2D space. We’ll randomly initialise this, it will be trained. Not that the
embedding dimensions can be larger than 2, it just makes it easier to visualise
the 2D space later. Again this is a hyper parameter we can tune.</p>

<textarea disabled rows='10'>
import {
    random,
    oneHot,
    transpose,
    softmaxByRow,
    negativeLogLikelihood,
    softmaxCrossEntropyGradient,
    sample
} from './1-bigram-utils.js';
</textarea>

<textarea disabled rows='4'>
hyperParameters.embeddingDimensions = 2;
const totalChars = indexToCharMap.length;
const CData = createFloatMatrix( [ totalChars, hyperParameters.embeddingDimensions ], random );
</textarea>

<p>How to we grab the embedding for a character? One way to grab the embedding for
a character is to use the character’s index.</p>

<textarea disabled rows='6'>
const indexOfB = stringToCharMap[ 'b' ];
const embeddingForB = [
    CData[ indexOfB * hyperParameters.embeddingDimensions + 0 ],
    CData[ indexOfB * hyperParameters.embeddingDimensions + 1 ],
];
</textarea>

<p>As we saw last time, this can also be accomplished by one-hot encoding the
character and then multiplying it by the embedding matrix.</p>

<textarea disabled rows='3'>
const oneHotForB = oneHot( [ indexOfB ], totalChars );
const embeddingForB = await matMul( oneHotForB, CData );
</textarea>

<p>However, the first method is more efficient. Let’s write a utility function.</p>

<textarea disabled rows='20' data-src="utils.js">
export function gather(A, indices) {
    const shape = indices.shape ?? [ indices.length ];
    if (A.shape.length !== 2) {
        const R = createFloatMatrix( shape );
        for (let i = indices.length; i--;) {
            R[i] = A[indices[i]];
        }
        return R;
    }
    const Dim = A.shape[1];
    const R = createFloatMatrix( [...shape, Dim] );
    for (let i = indices.length; i--;) {
        const index = indices[i];
        for (let j = Dim; j--;) {
            R[i * Dim + j] = A[index * Dim + j];
        }
    }
    return R;
}
</textarea>

<textarea disabled rows='2'>
const embeddingForB = gather( CData, new Int32Array( [ indexOfB ] ) );
</textarea>

<p>Now we can easily grab the embeddings for each context character in the input.</p>

<textarea disabled rows='2'>
const CX = gather( CData, X );
</textarea>

<p>Now we’ll initialize the weights and biases for the MLP.</p>

<textarea disabled rows='5'>
hyperParameters.neurons = 100;
const { embeddingDimensions, blockSize, neurons } = hyperParameters;
const W1Data = createFloatMatrix( [ embeddingDimensions * blockSize, neurons ], random );
const b1Data = createFloatMatrix( [ neurons ], random );
</textarea>

<p>But how can we multiply these matrices together? We must re-shape (essentially
flatten) the CX matrix so that the embeddings for each character in the block
size forms a single row.</p>

<textarea disabled rows='3'>
const { embeddingDimensions, blockSize } = hyperParameters;
const CXReshaped = new FloatMatrix( CX ).reshape( [ X.shape[ 0 ], embeddingDimensions * blockSize ] );
</textarea>

<p>Now we can multiply the matrices, add the biases, and apply the element-wise
tanh activation function. This forms the hidden layer.</p>

<textarea disabled rows='16' data-src="utils.js">
export async function matMulBias( A, B, bias ) {
    const data = await matMul(A, B);
    if ( ! bias ) return data;
    const [ m, n ] = data.shape;
    if (n !== bias.length ) {
        throw new Error('Bias vector dimension does not match the resulting matrix rows.');
    }
    // Add the biases to every row.
    for ( let m_ = m; m_--; ) {
        for ( let n_ = n; n_--; ) {
            data[ m_ * n + n_ ] += bias[ n_ ];
        }
    }
    return data;
}
</textarea>

<textarea disabled rows='4'>
const h = await matMulBias( CXReshaped, W1Data, b1Data );
// Activation function.
for ( let i = h.length; i--; ) h[ i ] = Math.tanh( h[ i ] );
</textarea>

<p>Output layer.</p>

<textarea disabled rows='12'>
const { neurons } = hyperParameters;
const W2Data = createFloatMatrix( [ neurons, totalChars ], random );
const b2Data = createFloatMatrix( [ totalChars ], random );
const logits = await matMul( h, W2Data );
const [ m, n ] = logits.shape;
// Add the biases to every row.
for ( let m_ = m; m_--; ) {
    for ( let n_ = n; n_--; ) {
        logits[ m_ * n + n_ ] += b2Data[ n_ ];
    }
}
</textarea>

<p>Softmax. Talk about what softmax cross entropy is, how it’s beneficial to
cluster for efficiency. As we saw in chapter 2, it’s a much more simple backward
pass.</p>

<textarea disabled rows='2'>
const probs = softmaxByRow( logits );
</textarea>

<p>Every row of <code class="language-plaintext highlighter-rouge">probs</code> sums to ~1.</p>

<textarea disabled rows='6'>
const row1 = createFloatMatrix( [ 1, totalChars ] );
for ( let i = totalChars; i--; ) {
    row1[ 0 * totalChars + i ] = probs[ 0 * totalChars + i ];
}
const sumOfRow1 = row1.reduce( ( a, b ) => a + b, 0 );
</textarea>

<p>Calculate the loss, which we’d like to minimize.</p>

<textarea disabled rows='2'>
const mean = negativeLogLikelihood( probs, Y );
</textarea>

<p>Great, we now have the forward pass. Let’s use the approach we saw in chapter 2
to automatically calculate the gradients.</p>

<p>There’s a few important differences from chapter 2.</p>

<ol>
  <li>Instead of scalar values, we now have matrices.</li>
  <li>The matMul operation on the GPU is asynchronous.</li>
</ol>

<p>Other than that, the code is largely the same. We also saw in chapter 1 how to
calculate the gradients for the matMul operation and softmax cross entropy. The
difference here is that we add the bias in a single operation for performance.
We also saw in chapter 2 how to calculate the gradients for the tanh activation
function.</p>

<p>Explain the gather operation.</p>

<textarea disabled rows='186' data-src="utils.js">
import { getTopologicalOrder } from './2-autograd-utils.js';
import {
    transpose,
    softmaxByRow,
    negativeLogLikelihood,
    softmaxCrossEntropyGradient,
} from './1-bigram-utils.js';
window.forwardTimes = [];
window.backwardTimes = [];
export class Value {
    static operations = new Map();
    _dependents = [];
    constructor(data, _children = [], _op) {
        this.data = data;
        this._op = _op;
        this._prev = _children;
        for ( const child of this._prev ) {
            if ( child instanceof Value ) child._dependents.push( this );
        }
    }

    static addOperation(operation, forward) {
        this.operations.set(operation, forward);
        this.prototype[operation] = function (...args) {
            return new Value(null, [this, ...args], operation);
        };
    }

    async _forward() {
        if (this._forwardReady) return this._forwardReady;

        this._forwardReady = (async () => {
            if (!this._op) {
                if (this.data === null) {
                    throw new Error("Leaf node has no data during forward pass.");
                }
                return this.data;
            }

            const args = this._prev;

            // Wait for all child nodes
            await Promise.all(args.map(arg => arg instanceof Value ? arg._forward() : null));

            const inputData = args.map(arg => arg instanceof Value ? arg.data : arg);

            const opFn = Value.operations.get(this._op);
            if (!opFn) throw new Error(`Missing operation handler for op: ${this._op}`);

            const start = performance.now();
            const [data, calculateGrad] = await opFn(...inputData);
            const end = performance.now();
            window.forwardTimes.push({ label: this._op, start, end });

            this.data = data;

            this._backward = async () => {
                const start = performance.now();
                const grads = await calculateGrad(this.grad);
                for (let i = 0; i < grads.length; i++) {
                    const child = args[i];
                    if (child instanceof Value) {
                        child.grad = child.grad ? add(child.grad, grads[i]) : grads[i];
                    }
                }
                const end = performance.now();
                window.backwardTimes.push({ label: this._op, start, end });
            };

            return data;
        })();

        return this._forwardReady;
    }

    async backward() {
        const reversed = getTopologicalOrder(this).reverse();

        for (const node of reversed) {
            node.grad = null;
        }

        this.grad = createFloatMatrix(this.data.shape ?? [1]).fill(1);

        for (const node of reversed) {
            await node._backward?.();
        }
    }

    // async backward() {
    //     // 1) topo‑sort & reverse to get “downstream → upstream”
    //     const revTopo = getTopologicalOrder(this).reverse();

    //     for (const node of revTopo) {
    //         node.grad = node === this ? createFloatMatrix(this.data.shape ?? [1]).fill(1) : null;
    //         node._backwardReady = (async () => {
    //             await Promise.all( node._dependents.map( async dep => await dep._backwardReady ) );
    //             if ( node._backward ) await node._backward();
    //         })();
    //     }

    //     await Promise.all( revTopo.map(node => node._backwardReady) );
    // }

    forward() {
        const order = getTopologicalOrder(this);

        for (const node of order) {
            delete node._forwardReady;
        }

        return this._forward();
    }
}

function add( A, B ) {
    if ( A.shape.toString() !== B.shape.toString() ) {
        throw new Error( 'Matrix dimensions do not match.' );
    }

    const C = new FloatMatrix( A );
    for ( let i = C.length; i--; ) C[ i ] += B[ i ];
    return C;
}

Value.addOperation( 'matMulBias', async ( A, B, bias ) => [
    await matMulBias( A, B, bias ),
    async ( grad ) => {
        const [ m, n ] = grad.shape;
        const biasGrad = createFloatMatrix( [ n ] );
        // Gradients for the biases are the sum of the gradients for
        // each row.
        for ( let m_ = m; m_--; ) {
            for ( let n_ = n; n_--; ) {
                biasGrad[ n_ ] += grad[ m_ * n + n_ ];
            }
        }
        return [
            await matMul( grad, transpose( B ) ),
            await matMul( transpose( A ), grad ),
            biasGrad
        ];
    }
] );

Value.addOperation( 'tanh', ( A ) => {
    const data = new FloatMatrix( A );
    for ( let i = data.length; i--; ) data[ i ] = Math.tanh( data[ i ] );
    return [
        data,
        ( grad ) => {
            const B = new FloatMatrix( grad );
            for ( let i = B.length; i--; ) B[ i ] *= ( 1 - Math.pow( data[ i ], 2 ) );
            return [B];
        }
    ];
} );

Value.addOperation( 'gather', ( A, indices ) => [
    gather( A, indices ),
    async ( grad ) => {
        const B = grad;
        let dA;
        if ( A.shape.length !== 2 ) {
            dA = createFloatMatrix( A.shape );
            for ( let i = B.length; i--; ) dA[ indices[i] ] += B[i];
        } else {
            dA = await scatterAdd( grad, indices, A.shape );
        }
        return [dA];
    }
] );

Value.addOperation( 'softmaxCrossEntropy', ( A, indices ) => {
    const data = softmaxByRow( A );
    return [
        negativeLogLikelihood( data, indices ),
        () => [ softmaxCrossEntropyGradient( data, indices ) ]
    ];
} );

Value.addOperation( 'reshape', ( A, shape ) => [
    new FloatMatrix( A ).reshape( shape ),
    ( grad ) => [ new FloatMatrix( grad ).reshape( A.shape ) ]
] );
</textarea>

<p>Now we can rebuild the mathematical operations we did before, and we should get
the same loss.</p>

<textarea disabled rows='17'>
function logitFn( X ) {
    const { embeddingDimensions, blockSize } = hyperParameters;
    const { C, W1, b1, W2, b2 } = params;
    const embedding = C.gather( X ).reshape( [ X.shape[ 0 ], embeddingDimensions * blockSize ] );
    const hidden = embedding.matMulBias( W1, b1 ).tanh();
    return hidden.matMulBias( W2, b2 );
}
const C = new Value( CData );
const W1 = new Value( W1Data );
const b1 = new Value( b1Data );
const W2 = new Value( W2Data );
const b2 = new Value( b2Data );
const params = { C, W1, b1, W2, b2 };
const loss = logitFn( X ).softmaxCrossEntropy( Y );
await loss.forward();
await loss.backward();
</textarea>

<p>Let’s calculate the gradients.</p>

<textarea disabled rows='3'>
hyperParameters.learningRate = 0.1;
const losses = [];
</textarea>

<textarea disabled rows='3'>
export { default as Plotly } from 'https://cdn.jsdelivr.net/npm/plotly.js-dist@2.26.2/+esm';
const graphs = [ document.createElement( 'div' ), document.createElement( 'div' ) ];
</textarea>

<textarea disabled rows='35'>
async function createLossesGraph( element, losses ) {
    await Plotly.react(
        element,
        [ { x: losses.map( ( _, i ) => i ), y: losses } ],
        {
            width: 500, height: 500,
            yaxis: { title: 'Loss', type: 'log' },
            xaxis: { title: 'Iterations' }
        },
        { displayModeBar: false }
    );
}
export async function createEmbeddingGraph( element, C ) {
    await Plotly.react(element, [
        {
            // get even indices from C.
            x: Array.from( C.data ).filter( ( _, i ) => i % 2 ),
            // get uneven indices from C.
            y: Array.from( C.data ).filter( ( _, i ) => ! ( i % 2 ) ),
            text: indexToCharMap,
            mode: 'markers+text',
            type: 'scatter',
            name: 'Embedding',
            marker: {
                size: 14,
                color: '#fff',
                line: { color: 'rgb(0,0,0)', width: 1 }
            }
        }
    ], {
        width: 500, height: 500,
        title: 'Embedding'
    });
}
</textarea>

<textarea disabled rows='15'>
const iterations = 5;
print(graphs);
for ( let i = 0; i < iterations; i++ ) {
    await loss.forward();
    losses.push( loss.data );
    await loss.backward();
    for ( const param of Object.values( params ) ) {
        for ( let i = param.data.length; i--; ) {
            param.data[ i ] -= hyperParameters.learningRate * param.grad[ i ];
        }
    }
    await createLossesGraph( graphs[0], losses );
    await createEmbeddingGraph( graphs[1], C );
}
</textarea>

<p>This runs very slowly!</p>

<h2 id="mini-batching">Mini-batching</h2>

<p>Instead of training on the entire dataset on every iteration, we can use a
subset of the dataset, called a mini-batch. This allows us to train on more data
in the same amount of time, speeding up training, and it can also help prevent
overfitting.</p>

<textarea disabled rows='15'>
const batchLosses = [];
function resetParameters() {
    const { embeddingDimensions, blockSize, neurons } = hyperParameters;
    const { C, W1, b1, W2, b2 } = params;
    C.data = createFloatMatrix( [ totalChars, embeddingDimensions ], random );
    W1.data = createFloatMatrix( [ embeddingDimensions * blockSize, neurons ], random );
    b1.data = createFloatMatrix( [ neurons ], random );
    W2.data = createFloatMatrix( [ neurons, totalChars ], random );
    b2.data = createFloatMatrix( [ totalChars ], random );
    losses.length = 0;
    batchLosses.length = 0;
}
resetParameters();
hyperParameters.batchSize = 32;
</textarea>

<p>It’s much better to have an appropriate gradient and take more steps than it is
to have an exact gradient and take fewer steps.</p>

<p>Now it’s important to note that the losses are for the mini-batch, not the
entire dataset. We coulde calculate the loss on the entire dataset, but not on
every iteration as this would slow us down. Instead we can calculate the loss
on the entire dataset once at the end.</p>

<textarea disabled rows='20' data-src="utils.js">
export async function createLossesGraph( element, batchLosses, losses ) {
    Plotly.react(element, [
        {
            y: batchLosses,
            name: 'Batch losses',
        },
        {
            y: losses,
            x: Array.from( losses ).map( ( _, i ) => ( i + 1 ) * batchLosses.length / losses.length ),
            name: 'Training losses',
        },
    ], {
        title: 'Losses',
        width: 500,
        height: 500,
        yaxis: { title: 'Loss', type: 'log' },
        xaxis: { title: 'Iterations' }
    });
}
</textarea>

<textarea disabled rows='5' data-src="utils.js">
export function miniBatch( X, Y, batchSize ) {
    const indices = Int32Array.from( { length: batchSize }, () => Math.random() * X.shape[ 0 ] );
    return [ gather( X, indices ), gather( Y, indices ) ];
}
</textarea>

<textarea disabled rows='24'>
const iterations = 100;
print(graphs);
for ( let i = 0; i < iterations; i++ ) {
    const [ Xbatch, Ybatch ] = miniBatch( X, Y, hyperParameters.batchSize );
    const loss = logitFn( Xbatch ).softmaxCrossEntropy( Ybatch );
    await loss.forward();
    batchLosses.push( loss.data );
    await loss.backward();
    for ( const param of Object.values( params ) ) {
        for ( let i = param.data.length; i--; ) {
            param.data[ i ] -= hyperParameters.learningRate * param.grad[ i ];
        }
    }

    if ( batchLosses.length % 100 === 0 ) {
        const loss = logitFn( X ).softmaxCrossEntropy( Y );
        await loss.forward();
        losses.push( loss.data );
    }

    await createLossesGraph( graphs[0], batchLosses, losses );
    await createEmbeddingGraph( graphs[1], C );
}
</textarea>

<p>If you run this 200-300 times, you’ll see that the embedding clusters together
the similar characters, such as the vowels, and the <code class="language-plaintext highlighter-rouge">.</code> will distance itself
from all other characters.</p>

<h2 id="learning-rate-decay">Learning rate decay</h2>

<p>Once it starts to plateau, we can reduce the learning rate an order of
magnitude.</p>

<textarea disabled rows='2'>
hyperParameters.learningRate = 0.01;
</textarea>

<p>Go back to the iterations and run again.</p>

<h2 id="splitting-the-dataset">Splitting the dataset</h2>

<p>As the capacity of the models increases (with more neurons, layers, etc), it
becomes more prone to overfitting. One way to combat this is to split the data
into training, validation, and test sets. The loss can get close to zero, but
all the the model is doing is memorizing the training data. We need to evaluate
against a validation set to see how well the model is performing.</p>

<p>Practically this means that, when sampling, we’ll only get names that exist in
the dataset. We won’t get any new sequences. The loss on names that are withheld
from the training set can be really high.</p>

<p>The standard split is 80% for training, 10% for validation (dev), and 10% for testing.</p>

<textarea disabled rows='8' data-src="utils.js">
export function shuffle( array ) {
  let i = array.length;
  while (i--) {
    const randomIndex = Math.floor(Math.random() * i);
    [array[i], array[randomIndex]] = [array[randomIndex], array[i]];
  }
}
</textarea>

<textarea disabled rows='8'>
shuffle( names );
const n1 = Math.floor( names.length * 0.8 );
const n2 = Math.floor( names.length * 0.9 );
const { blockSize } = hyperParameters;
const [ Xtr, Ytr ] = buildDataSet( names.slice( 0, n1 ), stringToCharMap, blockSize );
const [ Xdev, Ydev ] = buildDataSet( names.slice( n1, n2 ), stringToCharMap, blockSize );
const [ Xte, Yte ] = buildDataSet( names.slice( n2 ), stringToCharMap, blockSize );
</textarea>

<textarea disabled rows='3'>
resetParameters();
hyperParameters.learningRate = 0.1;
</textarea>

<textarea disabled rows='24'>
const iterations = 100;
print(graphs);
for ( let i = 0; i < iterations; i++ ) {
    const [ Xbatch, Ybatch ] = miniBatch( Xtr, Ytr, hyperParameters.batchSize );
    const loss = logitFn( Xbatch ).softmaxCrossEntropy( Ybatch );
    await loss.forward();
    batchLosses.push( loss.data );
    await loss.backward();
    for ( const param of Object.values( params ) ) {
        for ( let i = param.data.length; i--; ) {
            param.data[ i ] -= hyperParameters.learningRate * param.grad[ i ];
        }
    }

    if ( batchLosses.length % 100 === 0 ) {
        const loss = logitFn( Xdev ).softmaxCrossEntropy( Ydev );
        await loss.forward();
        losses.push( loss.data );
    }

    await createLossesGraph( graphs[0], batchLosses, losses );
    await createEmbeddingGraph( graphs[1], C );
}
</textarea>

<h2 id="increasing-the-embedding-size">Increasing the embedding size</h2>

<p>The bottleneck seems to be the embedding size.</p>

<p>Right now every character is put on a 2d plane. Let’s try a 3d embedding.</p>

<textarea disabled rows='3'>
hyperParameters.embeddingDimensions = 3;
resetParameters();
</textarea>

<textarea disabled rows='19'>
async function create3DEmbeddingGraph( element, C ) {
    await Plotly.react(element, [
        {
            x: Array.from( C.data ).filter( ( _, i ) => i % 3 === 0 ),
            y: Array.from( C.data ).filter( ( _, i ) => i % 3 === 1 ),
            z: Array.from( C.data ).filter( ( _, i ) => i % 3 === 2 ),
            text: indexToCharMap,
            mode: 'markers+text',
            type: 'scatter3d',
            name: 'Embedding',
            marker: { size: 5, color: '#000' }
        }
    ], {
        width: 500,
        height: 500,
        title: 'Embedding'
    });
}
</textarea>

<textarea disabled rows='24'>
const iterations = 100;
print(graphs);
for ( let i = 0; i < iterations; i++ ) {
    const [ Xbatch, Ybatch ] = miniBatch( Xtr, Ytr, hyperParameters.batchSize );
    const loss = logitFn( Xbatch ).softmaxCrossEntropy( Ybatch );
    await loss.forward();
    batchLosses.push( loss.data );
    await loss.backward();
    for ( const param of Object.values( params ) ) {
        for ( let i = param.data.length; i--; ) {
            param.data[ i ] -= hyperParameters.learningRate * param.grad[ i ];
        }
    }

    if ( batchLosses.length % 100 === 0 ) {
        const loss = logitFn( Xdev ).softmaxCrossEntropy( Ydev );
        await loss.forward();
        losses.push( loss.data );
    }

    await createLossesGraph( graphs[0], batchLosses, losses );
    await create3DEmbeddingGraph( graphs[1], C );
}
</textarea>

<h2 id="excercise-try-different-hyperparameters">Excercise: try different hyperparameters</h2>

<ul>
  <li>even higher embedding dimensions</li>
  <li>more or less neurons</li>
  <li>batch size</li>
  <li>higher context length</li>
  <li>Play with learning rate decay.</li>
</ul>

<textarea disabled rows='2'>
print(hyperParameters);
</textarea>

<h2 id="sample-names">Sample names</h2>

<textarea disabled rows='18'>
export const names = [];
const { blockSize } = hyperParameters;

for (let i = 0; i < 5; i++) {
    let out = Array( blockSize ).fill( 0 );

    do {
        const context = new FloatMatrix( out.slice( -blockSize ) ).reshape( [ 1, blockSize ] );
        const logits = logitFn( context );
        await logits.forward();
        const probs = softmaxByRow( logits.data );
        const ix = sample( probs );
        out.push( ix );
    } while ( out[ out.length - 1 ] !== 0 );

    names.push( out.slice( blockSize, -1 ).map( ( i ) => indexToCharMap[ i ] ).join( '' ) );
}
</textarea>


</article>
<script src="lib/acorn.min.js"></script>
<script src="common.js"></script>
<link rel="stylesheet" href="lib/codemirror.min.css" integrity="sha512-uf06llspW44/LZpHzHT6qBOIVODjWtv4MxCricRxkzvopAlSWnTf6hpZTFxuuZcuNE9CBQhqE0Seu1CoRk84nQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<script src="lib/codemirror.min.js" integrity="sha512-8RnEqURPUc5aqFEN04aQEiPlSAdE0jlFS/9iGgUyNtwFnSKCXhmB6ZTNl7LnDtDWKabJIASzXrzD0K+LYexU9g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="lib/javascript.min.js" integrity="sha512-I6CdJdruzGtvDyvdO4YsiAq+pkWf2efgd1ZUSK2FnM/u2VuRASPC7GowWQrWyjxCZn6CT89s3ddGI+be0Ak9Fg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<style>
    .CodeMirror, .CodeMirror-scroll {
        height: auto;
        background: none;
    }
</style>
<script>
    document.querySelectorAll('textarea').forEach((textarea) => {
        textarea.editor = CodeMirror.fromTextArea(textarea, {
            mode: 'javascript',
            viewportMargin: Infinity,
            // theme: 'material',
            extraKeys: {
                'Shift-Enter': (cm) => {
                    textarea.button.focus();
                },
            },
        });
    })
</script>







  <a href="autograd">Previous: 2. Autograd</a>


<!-- Debug: 
    Original: /makemore-learning-rate
    After remove_first: makemore-learning-rate
    After relative_url: /makemore-learning-rate
  -->
  <a href="makemore-learning-rate">Next: 3.1. makemore: Learning Rate</a>

<nav>
    <!-- <details> -->
        <!-- <summary>Table of contents</summary> -->
        <ul>
            
            <li><a href="">1. makemore: bigram</a></li>
            
            <li><a href="autograd">2. Autograd</a></li>
            
            <li><a href="makemore-MLP">3. makemore: MLP</a></li>
            
            <li><a href="makemore-learning-rate">3.1. makemore: Learning Rate</a></li>
            
            <li><a href="makemore-initialisation">3.2. makemore: Initialisation</a></li>
            
            <li><a href="makemore-batch-norm">3.3. makemore: Batch Norm</a></li>
            
            <li><a href="makemore-layer-organisation">3.4. makemore: Layer Organisation</a></li>
            
            <li><a href="diagnostic-tools">3.5. Diagnostic Tools</a></li>
            
            <li><a href="backprop-ninja">4. Backprop Ninja</a></li>
            
            <li><a href="makemore-wavenet">5. makemore: WaveNet</a></li>
            
            <li><a href="transformer">6. Transformer</a></li>
            
        </ul>
    <!-- </details> -->
</nav>
<script async src="lib/tex-mml-chtml.js"></script>
