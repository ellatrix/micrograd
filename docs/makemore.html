<p>Click <em>Sample</em>, and you'll see the output is very random, because the
neural network hasn't trained yet. Now click <em>Run</em> to start training (<a
href="https://raw.githubusercontent.com/karpathy/makemore/master/names.txt">data</a>).
When the loss is under 3, click <em>Sample</em> again, and you'll see the output
has gotten a bit better. Try to reach a loss of 2.7 or lower, but it's possible
to get it under 2.5! Note that the neural network tries to predict only based on
the previous character, so it won't get very good!</p>
<p>Excluding the table rendering this neural network is 300 lines of code and
has zero dependencies.</p>
<input type="text" id="learningRateInput" value="1">
<button id="runButton">Run</button>
<code>loss: </code><samp id="lossOutput">x.xxxx</samp>;
<code>iterations: </code><samp id="iterationsOutput">x</samp><hr>
<button id="sampleButton">Sample</button>
<samp id="sampleOutput"></samp>
<hr>
<table id="table"></table>
<script src="matmul-cpu.js"></script>
<script src="matmul-gpu.js"></script>
<script src="matrix.js"></script>
<script src="table.js"></script>
<script>
    function oneHot( a, length ) {
        const B = empty( [ a.length, length ] );
        for ( let i = a.length; i--; ) B[ i * length + a[ i ] ] = 1;
        return B;
    }

    function randomMinMax(min, max) {
        return Math.random() * (max - min) + min;
    }

    function random( shape ) {
        const A = empty( shape );
        for ( let i = A.length; i--; ) A[ i ] = randomMinMax( -1, 1 );
        return A;
    }

    function sample(probs) {
        const sum = probs.reduce((a, b) => a + b, 0)
        if (sum <= 0) throw Error('probs must sum to a value greater than zero')
        const normalized = probs.map(prob => prob / sum)
        const sample = Math.random()
        let total = 0
        for (let i = 0; i < normalized.length; i++) {
            total += normalized[i]
            if (sample < total) return i
        }
    }

    ( async () => {
        const res = await fetch('https://raw.githubusercontent.com/karpathy/makemore/master/names.txt');
        const text = await res.text();
        Layer.gpu = await GPU();
        const names = text.split('\n');
        const chars = [ ...new Set( names.join('') ) ].sort();
        const totalChars = chars.length + 1;
        const stringToCharMap = chars.reduce( ( map, char, index ) => {
            map[ char ] = index + 1;
            return map;
        }, {} );
        stringToCharMap[ '.' ] = 0;
        indexToCharMap = [ '.', ...chars ];

        // Inputs.
        const xs = [];
        // Targets, or labels.
        const ys = [];

        for ( const name of names ) {
            const exploded = '.' + name + '.';
            i = 1;
            while ( exploded[ i ] ) {
                const bigram = exploded[i - 1] + exploded[i];
                const indexOfChar1 = stringToCharMap[ exploded[ i - 1 ] ];
                const indexOfChar2 = stringToCharMap[ exploded[ i ] ];
                xs.push( indexOfChar1 );
                ys.push( indexOfChar2 );
                i++;
            }
        }

        const neurons = totalChars;
        // One hidden layer.
        const W = new Layer( random( [ totalChars, neurons ] ) );
        const xenc = new Layer( oneHot( xs, totalChars ) );
        const logits = xenc.matMul( W ); // = log counts
        const loss = logits.softmaxCrossEntropy( oneHot( ys, totalChars ) );
        const iterations = 200;
        let totalIterations = 0;
        let lastLoss = Infinity;
        let running = false;

        makeTable( W.data );

        runButton.onclick = () => {
            if ( running ) {
                running = false;
                runButton.textContent = 'Run';
                learningRateInput.disabled = false;
                return;
            }

            running = true;
            runButton.textContent = 'Stop';
            learningRateInput.disabled = true;

            const learningRate = parseFloat( learningRateInput.value ) || 0.1;
            const singleRun = async () => {
                await loss.forward();
                const lossValue = loss.data[0];
                const action = lossValue < lastLoss ? 'log' : 'error';
                console[action](`Loss after iteration ${i}: ${lossValue}`);
                lastLoss = lossValue;
                if ( action === 'error' && i > 5 ) {
                    learningRateInput.value = learningRate / 10;
                    running = false;
                    runButton.textContent = 'Run';
                    learningRateInput.disabled = false;
                    alert( `Loss increased. Try a lower learning rate. Suggested ${ learningRate / 10 }. Click "Run" to continue with the new rate.` );
                    return;
                }
                await loss.backward();
                for ( let i = W.data.length; i--; ) W.data[ i ] -= learningRate * W.grad[ i ];
                lossOutput.innerText = lossValue.toFixed( 4 );
                totalIterations++;
                iterationsOutput.innerText = totalIterations;
                makeTable( W.data );
            }

            let i = 0;

            const callback = async () => {
                if ( running && i++ < iterations ) {
                    await singleRun();
                    requestAnimationFrame( callback );
                } else {
                    running = false;
                    runButton.textContent = 'Run';
                    learningRateInput.disabled = false;
                }
            }

            requestAnimationFrame( callback );
        }

        sampleButton.onclick = () => {
            const names = [];

            for (let i = 0; i < 5; i++) {
                const out = []  
                let ix = 0;

                while ( true ) {
                    const xenc = oneHot( [ ix ], totalChars );
                    const logits = matMul( xenc, W.data );
                    const probs = softmaxByRow( logits );
                    ix = sample( probs );

                    out.push( indexToCharMap[ ix ] );

                    if ( ix === 0 ) {
                        break;
                    }
                }

                names.push( out.join( '' ).slice( 0, -1 ) );
            }

            sampleOutput.innerText = names.join( ', ' );
        }
    })();
</script>